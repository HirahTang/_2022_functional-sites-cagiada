{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <b><font color='#009e74'>Variant/Residue effect class prediction via mutational scanning.</font></b>\n",
        "Colaboratory implementation of : **Cagiada, et al.,** [Discovering functionally important sites in proteins\n",
        "](https://www.biorxiv.org/content/10.1101/2022.07.14.500015v1.full). Source code is available on the project [Github](https://github.com/KULL-Centre/_2022_functional-sites-cagiada) page.\n",
        "\n",
        "Prediction of protein variants and residues on stability and function via evaluation of mutation effects. The program requires as input:\n",
        "- **thermodynamic stability evaluation** ($\\Delta \\Delta G$ in kcal/mol) generated via e.g. Rosetta or [RaSP](https://github.com/KULL-Centre/papers/tree/main/2022/ML-ddG-Blaabjerg-et-al);\n",
        "- the query protein **structure** (experimental crystal structure or AF2 prediction, in PDB format); \n",
        "- **conservation scores** ($\\Delta \\Delta E$) generated using [GEMME](https://academic.oup.com/mbe/article/36/11/2604/5548199?login=true), which can be generated in the official [webserver](http://www.lcqb.upmc.fr/GEMME/submit.html). \n",
        "The output files generated will include input features per variant, prediction per variants and prediction per positions."
      ],
      "metadata": {
        "id": "suTWcMj_Q5L7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  <b><font color='#009e74'> Reminders and Important informations:</font></b>\n",
        "- This notebook  <b><font color='#d55c00'>can </font></b> be run without using a Colab GPU session (to do: go to page menu: `Runtime`->  `Change runtime type` -> select `CPU` and confirm)\n",
        "- Cells named as  <b><font color='#f0e422'>PRELIMINARY OPERATIONS </font></b> have to be run <b><font color='#d55c00'>ONCE only at the start</font></b>  and  skipped for new predictions.\n",
        "- <b><font color='#d55c00'>ONE</font></b> single protein at the time can be processed by the pipeline, but re-running the **Load sequence** cell allows to run multiple proteins in series. \n",
        "- <b><font color='#d55c00'>Each protein</font></b> requires a series of input from outside and specific formatted file. Please check the file format on the [Github](https://github.com/KULL-Centre/_2022_functional-sites-cagiada) repository.\n",
        "-  <b><font color='#56b4e9'>Query sequence</font></b> is the reference sequence for the protein during the analysis. Scores for GEMME, $\\Delta \\Delta G$ and structure features should be evaluated on the query sequence. If this is not possible, the query sequence and the specific score sequence will be align and only matching residues will be consider for the analysis.\n",
        "\n",
        "****"
      ],
      "metadata": {
        "id": "V6ITSjSWImmB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gu1FE5ur7RTs",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color='#f0e422'>PRELIMINARY OPERATIONS:</font> Install dependencies\n",
        "#@markdown Run the cell to install all the extra necessaries packages, including:\n",
        "#@markdown - catboost (0.26.1 - version used in the manuscript)\n",
        "#@markdown - MDtraj\n",
        "#@markdown - Biopython\n",
        "\n",
        "%%bash -s\n",
        "\n",
        "if [ ! -f COLABFOLD_READY ]; then\n",
        "  # install dependencies\n",
        "  pip install -q catboost==0.26.1 ## same version used in the paper\n",
        "  pip install -q mdtraj\n",
        "  pip install -q Biopython\n",
        "\n",
        "fi\n",
        "\n",
        "wget -cq https://github.com/KULL-Centre/_2022_functional-sites-cagiada/raw/main/catboost_model/cat_param_trained.zip\n",
        "\n",
        "unzip cat_param_trained.zip \n",
        "\n",
        "rm cat_param_trained.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#f0e422'>PRELIMINARY OPERATIONS:</font> Load pipeline functions\n",
        "#@markdown Run the cell to load the required functions\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mdtraj as md\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import os,shutil\n",
        "from google.colab import files\n",
        "from Bio import Align\n",
        "\n",
        "## dictionaries\n",
        "alphabetAA_L_D={'-':0,'_' :0,'A':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'K':9,'L':10,'M':11,'N':12,'P':13,'Q':14,'R':15,'S':16,'T':17,'V':18,'W':19,'Y':20}\n",
        "alphabetAA_D_L={v: k for k, v in alphabetAA_L_D.items()}\n",
        "\n",
        "AA_to_hydrophobicity_scores={'A':44,'C':50,'D':-37,'E':-12,'F':96,'G':0,'H':-16,'I':100,'K':-30,'L':99,'M':74,'N':-35,'P':-46,'Q':-14,'R':-20,'S':-6,'T':13,'V':78,'W':90,'Y':57}\n",
        "\n",
        "alphabet_class_variant_d_l={0:'WT-like',1:'SBI',2:'Total-loss'}\n",
        "alphabet_class_residue_d_l={0:'WT-like',1:'Functional site',2:'Total-loss',5:'Not assgined'}\n",
        "\n",
        "aa_order_alphabetical = pd.Series([\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\",\n",
        "           \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"W\", \"Y\"])\n",
        "\n",
        "alphabetAA_L_D_reordered={0:'R',1:'H',2:'K',3:'D',4:'E',5:'S',6:'T',7:'N',8:'Q',9:'C',10:'G',11:'P',12:'A',13:'V',14:'I',15:'L',16:'M',17:'F',18:'Y',19:'W'}\n",
        "alphabetAA_D_D_reordered={14:0,6:1,8:2,2:3,3:4,15:5,16:6,11:7,13:8,1:9,5:10,12:11,0:12,17:13,7:14,9:15,10:16,4:17,19:18,18:19}\n",
        "\n",
        "## functions\n",
        "\n",
        "def remove_WT_score(score,WT_seq):\n",
        "    for i in range(len(WT_seq)):\n",
        "        score[i,alphabetAA_L_D[WT_seq[i]]-1]=np.nan\n",
        "    return score\n",
        "\n",
        "def load_data(data,wt_seq,column_score=1,print_sequences=False):\n",
        "    df=pd.read_csv(data, delim_whitespace=True, comment='#')\n",
        "    mutation_load=np.array(df.iloc[:,0])\n",
        "    score_load=np.array(df.iloc[:,column_score])\n",
        "\n",
        "    pos=1\n",
        "    data_wt=''\n",
        "    for i in range(len(mutation_load)):\n",
        "        if i==0:\n",
        "            pos=int(mutation_load[i][1:-1])\n",
        "            if pos ==1:\n",
        "                data_wt=data_wt+str(mutation_load[i][0])\n",
        "            else:\n",
        "                data_wt=data_wt+'-'*(pos-1)+str(mutation_load[i][0])\n",
        "        else:\n",
        "            #print(pos,int(mutation_load[i][1:-1]))\n",
        "            if pos!= int(mutation_load[i][1:-1]):\n",
        "                diff= int(mutation_load[i][1:-1]) - pos\n",
        "                if diff ==1:\n",
        "                    data_wt=data_wt+str(mutation_load[i][0])\n",
        "                else:\n",
        "                    data_wt=data_wt+'-'*(diff-1)+str(mutation_load[i][0])\n",
        "                pos=int(mutation_load[i][1:-1])\n",
        "\n",
        "    if wt_seq is None:\n",
        "        wt_seq=data_wt\n",
        "    aligner = Align.PairwiseAligner()\n",
        "    alignments = aligner.align(wt_seq, data_wt)\n",
        "    if print_sequences:\n",
        "      print('query = wt_sequence / target: file_sequence')\n",
        "      print(alignments[0])\n",
        "    aligned_seqs=alignments[0].aligned\n",
        "\n",
        "    scores=np.empty((len(data_wt),20),dtype=float)\n",
        "    scores[:]=np.nan\n",
        "    \n",
        "    for i in range(len(mutation_load)):\n",
        "        if mutation_load[i][len(mutation_load[i])-1]!= '=':\n",
        "            scores[int(mutation_load[i][1:len(mutation_load[i])-1])-1, alphabetAA_L_D[mutation_load[i][len(mutation_load[i])-1]]-1]= float(score_load[i])\n",
        "    \n",
        "    scores_aligned=np.empty((len(wt_seq),20),dtype=float)\n",
        "    scores_aligned[:]=np.nan\n",
        "    \n",
        "    for r in range(len(aligned_seqs[0])):\n",
        "        scores_aligned[aligned_seqs[0,r][0]:aligned_seqs[0,r][1],:]=scores[aligned_seqs[1,r][0]:aligned_seqs[1,r][1],:]\n",
        "    \n",
        "    \n",
        "    return scores_aligned\n",
        "\n",
        "def WCN(pdb_loc,scheme_e,WT,chain=0,print_sequences=False):\n",
        "    r0=7.0\n",
        "    pdb=md.load(pdb_loc)\n",
        "    topology=pdb.topology\n",
        "    \n",
        "    chainA=topology.select(f'chainid {chain} and protein')\n",
        "    \n",
        "    pdb_seq=topology.to_fasta(chain)\n",
        "    \n",
        "    pdb_chain0=pdb.atom_slice(chainA)\n",
        "    pdb_dist,pdb_rp=md.compute_contacts(pdb_chain0,scheme=scheme_e,periodic=False)\n",
        "  \n",
        "    cm= md.geometry.squareform(pdb_dist,pdb_rp)[0]\n",
        "    wcn=np.zeros((len(WT)),dtype=float)\n",
        "    \n",
        "    cm_adj=np.empty((len(WT),len(WT)),dtype=float)\n",
        "    cm_adj[:]=np.nan\n",
        "    \n",
        "    chainA_top=pdb_chain0.topology\n",
        "    aligner = Align.PairwiseAligner()\n",
        "    alignments = aligner.align(WT, pdb_seq)\n",
        "    \n",
        "    aligned_seqs=alignments[0].aligned\n",
        "    \n",
        "    if print_sequences:\n",
        "      print('query = wt_sequence / target: file_sequence')\n",
        "      print(alignments[0])\n",
        "    for r1 in range(len(aligned_seqs[0])):\n",
        "      for r2 in range(len(aligned_seqs[0])):\n",
        "        cm_adj[aligned_seqs[0,r1][0]:aligned_seqs[0,r1][1],aligned_seqs[0,r2][0]:aligned_seqs[0,r2][1]]= cm[aligned_seqs[1,r1][0]:aligned_seqs[1,r1][1],aligned_seqs[1,r2][0]:aligned_seqs[1,r2][1]]\n",
        "\n",
        "    for i in range(len(WT)):\n",
        "      nan_flag=True\n",
        "      for j in range(len(WT)):\n",
        "        if np.isnan(cm_adj[i,j])!=True and cm_adj[i,j]!=0.0:\n",
        "          nan_flag=False\n",
        "          wcn[i]+=(1-(cm_adj[i,j]*10/r0)**6)/(1-(cm_adj[i,j]*10/r0)**12)\n",
        "      if nan_flag==True:\n",
        "        wcn[i]=np.nan\n",
        "    return wcn\n",
        "\n",
        "def neighbor_scores(score,ext_range):\n",
        "  score_neighborhood=np.zeros(len(score),dtype=float)\n",
        "  for i in range(len(score)):\n",
        "      if np.isnan(score[i])!=True:\n",
        "          count_nan=0\n",
        "          if i==0:\n",
        "              for j in range(1,ext_range+1):\n",
        "                  if np.isnan(score[j])==False:\n",
        "                      score_neighborhood[i]+=score[j]\n",
        "                  else:\n",
        "                      count_nan+=1\n",
        "              if count_nan!=ext_range:    \n",
        "                  score_neighborhood[i]/=(ext_range)\n",
        "              else:\n",
        "                  score_neighborhood[i]=np.nan\n",
        "\n",
        "          elif i==(len(score)-1):\n",
        "              for j in range(len(score)-1-ext_range,len(score)-1):\n",
        "                  if np.isnan(score[j])==False:\n",
        "                      score_neighborhood[i]+=score[j]\n",
        "                  else:\n",
        "                      count_nan+=1\n",
        "              if count_nan!=ext_range: \n",
        "                  score_neighborhood[i]/=ext_range\n",
        "              else:\n",
        "                  score_neighborhood[i]=np.nan                \n",
        "          elif i<ext_range:\n",
        "              for j in range(0,i+ext_range+1):\n",
        "                  if j!=i:\n",
        "                      if np.isnan(score[j])==False:\n",
        "                          score_neighborhood[i]+=score[j]\n",
        "                      else:\n",
        "                          count_nan+=1\n",
        "              if count_nan!=(i+ext_range):    \n",
        "                  score_neighborhood[i]/=(i+ext_range)\n",
        "              else:\n",
        "                  score_neighborhood[i]=np.nan                        \n",
        "\n",
        "          elif i>(len(score)-1-ext_range):\n",
        "              for j in range(i-ext_range,len(score)):\n",
        "                  if j!=i:\n",
        "                      if np.isnan(score[j])==False:\n",
        "                          score_neighborhood[i]+=score[j]\n",
        "                      else:\n",
        "                          count_nan+=1\n",
        "              if count_nan!=(len(score)-i+ext_range):                     \n",
        "                  score_neighborhood[i]/=(len(score)-i+ext_range)\n",
        "              else:\n",
        "                  score_neighborhood[i]=np.nan  \n",
        "          else:\n",
        "              for j in range(i-ext_range,i+ext_range+1):\n",
        "                  if j!=i:\n",
        "                      if np.isnan(score[j])==False:\n",
        "                          score_neighborhood[i]+=score[j]\n",
        "                      else:\n",
        "                          count_nan+=1\n",
        "              if count_nan!=(2*ext_range):  \n",
        "                  score_neighborhood[i]/=(2*ext_range)\n",
        "              else:\n",
        "                  score_neighborhood[i]=np.nan             \n",
        "      else:\n",
        "          score_neighborhood[i]=np.nan\n",
        "  return score_neighborhood\n",
        "\n",
        "def normalize_cutoff(scores,lowcut,highcut):\n",
        "  normalized_scores=np.copy(scores)\n",
        "  for i in range(scores.shape[0]):\n",
        "      for j in range(scores.shape[1]):\n",
        "          if scores[i,j] < lowcut:\n",
        "              normalized_scores[i,j]=lowcut\n",
        "          elif scores[i,j] > highcut:\n",
        "              normalized_scores[i,j]=highcut\n",
        "          else:\n",
        "              normalized_scores[i,j]=scores[i,j]\n",
        "  return normalized_scores\n",
        "\n",
        "def position_mean(score):\n",
        "  score_mean=np.zeros(score.shape[0],dtype=float)\n",
        "  for i in range(score.shape[0]):\n",
        "      count=0\n",
        "      flag_nan=True\n",
        "      for j in range(score.shape[1]):\n",
        "          if np.isnan(score[i,j])==False:\n",
        "              flag_nan=False\n",
        "              score_mean[i]+=score[i,j]\n",
        "              count+=1\n",
        "          else:\n",
        "              pass\n",
        "      if flag_nan==True:\n",
        "          score_mean[i]=np.nan\n",
        "      score_mean[i]/=count\n",
        "      \n",
        "  return score_mean\n",
        "\n",
        "def features_validation(list_features_x,WT):\n",
        "    \n",
        "  X=[]\n",
        "  mapping_pos=[] \n",
        "  \n",
        "  for i in range(len(WT)):\n",
        "      for j in range(20):\n",
        "          if j!=(alphabetAA_L_D[WT[i]]-1):\n",
        "            \n",
        "              temp_x=[]\n",
        "              temp_y=[]\n",
        "              cond=True\n",
        "\n",
        "              for elem in list_features_x:\n",
        "                  if elem.ndim==1:\n",
        "                      if np.isnan(elem[i])==True:\n",
        "                          cond=False\n",
        "                  else:\n",
        "                      if np.isnan(elem[i,j])==True:\n",
        "                          cond=False    \n",
        "          \n",
        "\n",
        "              if cond==True:\n",
        "                  \n",
        "                  for elem in list_features_x:\n",
        "                      if elem.ndim==1:\n",
        "                          temp_x.append(elem[i])\n",
        "                      else:\n",
        "                          temp_x.append(elem[i,j])\n",
        "              if len(temp_x)>0:\n",
        "                  X.append(temp_x)\n",
        "                  mapping_pos.append([i,j])\n",
        "      \n",
        "  return np.array(X),mapping_pos\n",
        "\n",
        "def retrieve_residue_label_pred(prediction,variant_map,WT,percentage_threshold):\n",
        "  scores=np.empty((len(WT),20),dtype=float)\n",
        "  scores[:]=np.nan\n",
        "  \n",
        "  i=0\n",
        "  for cord in variant_map:\n",
        "      scores[cord[0],cord[1]]=prediction[i]\n",
        "      i+=1\n",
        "  \n",
        "  count_pos=np.zeros((len(WT),4),dtype=float)\n",
        "  \n",
        "  pseudomode_value_class=np.empty(len(WT),dtype=float)\n",
        "  pseudomode_value_class[:]=np.nan\n",
        "  percentage=np.zeros((len(WT),2),dtype=float)\n",
        "      \n",
        "  for i in range(len(pseudomode_value_class)):\n",
        "      count=0\n",
        "      for j in range(scores.shape[1]):\n",
        "          if np.isnan(scores[i,j])!=True:\n",
        "              count+=1\n",
        "      if count>0:\n",
        "          for j in range(scores.shape[1]):\n",
        "                  if np.isnan(scores[i,j])!=True:\n",
        "                      count_pos[i,int(scores[i,j])]+=1\n",
        "          count_pos=count_pos/count\n",
        "          if np.any(count_pos[i,:]>=0.50):\n",
        "              pseudomode_value_class[i]=np.argmax(count_pos[i,:])\n",
        "              percentage[i,0]=count_pos[i,1]\n",
        "              #print(i, count_pos[i,:],np.max(count_pos[i,:]),np.argmax(count_pos[i,:]),pseudomode_value_class[i])\n",
        "\n",
        "\n",
        "          else:                \n",
        "              pseudomode_value_class[i]=5\n",
        "              percentage[i,0]=count_pos[i,1]\n",
        "              ## 5 indicates mixed signal with no predominat mutation class\n",
        "          \n",
        "          percentage[i,1]=count\n",
        "    \n",
        "  return pseudomode_value_class\n",
        "\n",
        "def count_class_variant_position(variant_matrix,pred_class):\n",
        "  variant_class_count=[]\n",
        "  for i in range(variant_matrix.shape[0]):\n",
        "    variant_class_count.append(np.count_nonzero((variant_matrix[i,:]==pred_class)))\n",
        "  return np.array(variant_class_count)\n",
        "\n",
        "\n",
        "def generate_empty_prism_df(seq):\n",
        "    variant_list = []\n",
        "    for wt, pos in zip(seq, range(len(seq))):\n",
        "        for mut in aa_order_alphabetical:\n",
        "            variant = str(wt) + str(pos+1) + str(mut)\n",
        "            variant_list.append(variant)\n",
        "\n",
        "    prism_df = pd.DataFrame({\"variant\" : variant_list, \"score\" : np.nan}, index = variant_list)\n",
        "    return(prism_df)\n",
        "\n",
        "def GEMME_to_prism(gemme_df, seq ,output_name , offset = 0):\n",
        "    prism_df = generate_empty_prism_df(seq)\n",
        "    gemme_df.index = aa_order_alphabetical\n",
        "    for pos in gemme_df.columns:\n",
        "        for aa in gemme_df.index:\n",
        "            p = int(str(pos)[1:])\n",
        "            wt = seq[p-1 + offset]\n",
        "            mut = str(aa).upper()\n",
        "            val = gemme_df.at[aa, pos]\n",
        "\n",
        "            variant = str(wt) + str(p) + str(mut)\n",
        "            #print(variant)\n",
        "            prism_df.loc[variant, \"score\"] = val\n",
        "\n",
        "    prism_df.reset_index(inplace = True, drop = True)\n",
        "    prism_df = prism_df.dropna()\n",
        "    prism_df.columns = [\"variant\", \"gemme_score\"]\n",
        "    prism_df.to_csv(output_name,index=False,sep=' ')\n",
        "    print(f'---> GEMME file converted')\n",
        "\n",
        "def histogram_data(data_input,range_data,xlabel,title,where_save):\n",
        "  fig,ax=plt.subplots(1,1,figsize=(6,4),layout='tight')\n",
        "  ax.hist(data_input,range=range_data,bins=20,edgecolor='k',facecolor='#56b4e9')\n",
        "  ax.set_xlabel(xlabel)\n",
        "  ax.set_ylabel('counts')\n",
        "  ax.set_title(title)\n",
        "\n",
        "  plt.savefig(os.path.join(where_save,title+'_histogram.png'),dpi=300,bbox_inches='tight')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def heatmap_classes_reordered(ext_score,label_cm,WT_mask,x,title_figure='',where_save='./',WT_cmap='gnuplot_r',nan_cmap='Dark2_r',figs=[30,7],xtick_spacing=10):\n",
        "    mpl.rcParams['xtick.labelsize'] = 18\n",
        "    mpl.rcParams['ytick.labelsize'] = 18\n",
        "    mpl.rcParams['axes.labelsize']  = 20\n",
        "\n",
        "    score=np.copy(ext_score)\n",
        "\n",
        "    for i in range(score.shape[1]):\n",
        "        #print(i,score[:,i][0:10])\n",
        "        score[:,alphabetAA_D_D_reordered[i]]=ext_score[:,i]\n",
        "        #print(alphabetAA_D_D_reordered[i],score[:,alphabetAA_D_D_reordered[i]][0:10])\n",
        "\n",
        "    score_nan=np.copy(ext_score)\n",
        "    score_nan[:]=np.inf\n",
        "    \n",
        "    for i in range(score.shape[0]):\n",
        "        for j in range(score.shape[1]):\n",
        "                if np.isnan(ext_score[i,j])==True and WT_mask[i]!=alphabetAA_D_L[j+1]:\n",
        "                    \n",
        "                    score_nan[i,alphabetAA_D_D_reordered[j]]=1\n",
        "                    #print(WT_mask[i],alphabetAA_D_D_reordered[alphabetAA_D_L[j+1]])\n",
        "            \n",
        "    fig, ax = plt.subplots(figsize=(figs[0],figs[1]),layout='tight')\n",
        "    ylabels=[ alphabetAA_L_D_reordered[i] for i in range(0,20)]\n",
        "    if np.isnan(np.unique(score)).any():\n",
        "      num_colors=len(np.unique(score))-1\n",
        "    else:\n",
        "      num_colors=len(np.unique(score))\n",
        "\n",
        "    if num_colors==3:\n",
        "      pos=ax.imshow(np.transpose(score), aspect = 'auto', cmap=mpl.colors.ListedColormap([\"#009e74\", \"#56b4e9\",\"#d55c00\"]),interpolation='nearest')\n",
        "    elif num_colors==4:\n",
        "      pos=ax.imshow(np.transpose(score), aspect = 'auto', cmap=mpl.colors.ListedColormap([\"#009e74\", \"#56b4e9\",\"#d55c00\",\"#f0e442\"]),interpolation='nearest')\n",
        "  \n",
        "    #current_cmap = mpl.cm.get_cmap()\n",
        "    current_cmap = plt.get_cmap()\n",
        "    current_cmap.set_bad(color='gray')\n",
        "\n",
        "    ax.set_yticks([i for i in range(0,20)])\n",
        "    ax.set_yticklabels(ylabels)\n",
        "    \n",
        "    #ax.xaxis.set_ticks(np.arange(1, end, stepsize))\n",
        "\n",
        "    plt.grid(axis='both',which='both',alpha=0.4)\n",
        "    #plt.ylabel(\"mutation\")\n",
        "    plt.xlabel(\"residue\")\n",
        "    plt.ylim(-0.5,19.5)\n",
        "    plt.xlim(x[0]-0.5,x[1]+0.5)\n",
        "    start, end = ax.get_xlim()\n",
        "    ax.xaxis.set_ticks(np.arange(start+0.5, end, xtick_spacing))\n",
        "    ax.tick_params(axis='x',rotation=90)\n",
        "    ax.tick_params(axis='y',rotation=90)\n",
        "    ax.set_title(title_figure,fontsize=20)\n",
        "    tmp=np.empty((len(WT_mask),20),dtype=float)\n",
        "    tmp[:]=np.inf\n",
        "    for i in range(0,len(WT_mask)):\n",
        "        tmp[i,alphabetAA_D_D_reordered[alphabetAA_L_D[WT_mask[i]]-1]]=1\n",
        "    \n",
        "    plt.imshow(score_nan.T, cmap=nan_cmap, aspect = 'auto',interpolation='nearest')\n",
        "    plt.imshow(tmp.T, cmap=WT_cmap, aspect = 'auto',interpolation='nearest')\n",
        "    plt.savefig(os.path.join(where_save,title_figure+'_variant_map.png'),dpi=300,bbox_inches='tight')\n",
        "    plt.show()\n",
        "def residues_classes_reordered(ext_score,x,title_figure='',where_save='./',figs=[20,1],xtick_spacing=10):\n",
        "  mpl.rcParams['xtick.labelsize'] = 18\n",
        "  mpl.rcParams['ytick.labelsize'] = 18\n",
        "  mpl.rcParams['axes.labelsize']  = 20\n",
        "  fig,ax1 = plt.subplots(1,1,figsize=(figs[0],figs[1]),layout='tight')\n",
        "\n",
        "  if 5. in ext_score:\n",
        "    ax1.imshow(ext_score.reshape(1,-1),aspect= 'auto', cmap=mpl.colors.ListedColormap([\"#009e74\", \"#56b4e9\",\"#d55c00\",\"#f0e442\",\"#5A5A5A\",\"#5A5A5A\"]))\n",
        "  else:\n",
        "    if 3. in ext_score:\n",
        "      ax1.imshow(ext_score.reshape(1,-1),aspect= 'auto', cmap=mpl.colors.ListedColormap([\"#009e74\", \"#56b4e9\",\"#d55c00\",\"#f0e442\"]))\n",
        "    else:\n",
        "      ax1.imshow(ext_score.reshape(1,-1),aspect= 'auto', cmap=mpl.colors.ListedColormap([\"#009e74\", \"#56b4e9\",\"#d55c00\"]))\n",
        "\n",
        "  ax1.set_yticks([])\n",
        "  plt.xlim(x[0]-0.5,x[1]+0.5)\n",
        "\n",
        "  start, end = ax1.get_xlim()\n",
        "  ax1.xaxis.set_ticks(np.arange(start+0.5, end, xtick_spacing))\n",
        "  ax1.tick_params(axis='x',rotation=90)\n",
        "\n",
        "  ax1.set_xlabel('residue')\n",
        "  ax1.set_title(title_figure,fontsize=20)\n",
        "  plt.savefig(os.path.join(where_save,title_figure+'_residue_class.png'),dpi=300,bbox_inches='tight')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "7L052N6sQ5ko",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'>DATA PREPROCESSING:</font> Load sequence\n",
        "#@markdown Input the query sequence and jobname for the target protein (it will be used for naming output files)\\\n",
        "#@markdown **N.B.: Re-rerunning the cell will delete previous runs and related uploaded input data.**\n",
        "from google.colab import files\n",
        "import os.path\n",
        "import re\n",
        "\n",
        "if 'input_path' in locals():\n",
        "  shutil.rmtree(input_path)\n",
        "\n",
        "query_sequence='SEQUENCE'#@param {type:\"string\"}\n",
        "\n",
        "if ' ' in query_sequence:\n",
        "  print('!!!! please check input sequence before proceeding: it may contains space characters !!!!')\n",
        "\n",
        "jobname='test'#@param {type:\"string\"}\n",
        "\n",
        "input_path = f\"{jobname}_inputs\"\n",
        "if not os.path.exists(input_path):\n",
        "  os.mkdir(input_path)\n",
        "\n",
        "\n",
        "output_path = f\"{jobname}_outputs\"\n",
        "if not os.path.exists(output_path):\n",
        "  os.mkdir(output_path)\n",
        "\n",
        "plot_folder=os.path.join(output_path,'figures')\n",
        "if not os.path.exists(plot_folder):\n",
        "  os.mkdir(plot_folder)\n",
        "\n",
        "\n",
        "loaded_ddg=False\n",
        "loaded_pdb=False\n",
        "loaded_gemme=False\n",
        "loaded_extra=False\n"
      ],
      "metadata": {
        "id": "erRk9OsbKttN",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'>DATA PREPROCESSING:</font> load $\\Delta \\Delta Gs$\n",
        "#@markdown Run the cell to open the upload request and load $\\Delta \\Delta G$ mutagenesis file (in kcal/mol) -  the file format description is shown on the bottom of the notebook.\\\n",
        "#@markdown \\\n",
        "#@markdown **Select $\\Delta \\Delta G$ source:**\n",
        "#@markdown - RaSP $\\Delta \\Delta G$s  (use the output file: \"prism_output_file\", [RaSP webserver](https://colab.research.google.com/github/KULL-Centre/papers/blob/main/2022/ML-ddG-Blaabjerg-et-al/RaSPLab.ipynb))\n",
        "#@markdown - Rosetta $\\Delta \\Delta Gs$ (already correctly formatted)\n",
        "\n",
        "ddG_file_format = \"RaSP\" #@param [\"Rosetta\", \"RaSP\"]\n",
        "#@markdown If the two sequences (query and input file) are different, the pipeline will align them and use only the matching position.\n",
        "\n",
        "print_aligned_sequences = True #@param {type:\"boolean\"}\n",
        "print('-> upload ddg file:')\n",
        "uploaded_ddg = files.upload()\n",
        "\n",
        "for fn in uploaded_ddg.keys():\n",
        "    os.rename(fn, f\"{jobname}_inputs/{fn}\")\n",
        "    \n",
        "    if ddG_file_format == 'Rosetta':\n",
        "      rosetta_scores=load_data(f\"{jobname}_inputs/{fn}\",query_sequence)\n",
        "    elif ddG_file_format == 'RaSP':\n",
        "      rosetta_scores=load_data(f\"{jobname}_inputs/{fn}\",query_sequence,column_score=2,print_sequences=print_aligned_sequences)\n",
        "    print('--> rosetta ddg score loaded')\n",
        "\n",
        "rosetta_scores=remove_WT_score(rosetta_scores,query_sequence)\n",
        "rosetta_scores_norm=normalize_cutoff(rosetta_scores,0,5)\n",
        "rosetta_scores_mean=np.nanmean(rosetta_scores_norm,axis=-1)\n",
        "\n",
        "print('---> rosetta mean evaluated')\n",
        "\n",
        "if ddG_file_format == 'Rosetta':\n",
        "  histogram_data(rosetta_scores.flatten(),range_data=[0,5],xlabel='Rosetta $\\Delta \\Delta G$ [kcal/mol]',title=jobname+'_Rosetta',where_save=plot_folder)\n",
        "elif ddG_file_format == 'RaSP':\n",
        "  histogram_data(rosetta_scores.flatten(),range_data=[0,5],xlabel='RaSP $\\Delta \\Delta G$ [kcal/mol]',title=jobname+'_RaSP',where_save=plot_folder)\n",
        "\n",
        "loaded_ddg = True\n"
      ],
      "metadata": {
        "id": "rGkpCzKs-zfp",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'>DATA PREPROCESSING:</font> load PDB file or AF2 predicted structure\n",
        "#@markdown Run the cell to open the upload request and load the structure of target protein in PDB format.\n",
        "\n",
        "#@markdown **Select input chain:**\n",
        " \n",
        "pdb_chain='0'#@param [\"0\",'1',\"2\",'3',\"4\",'5',\"6\",'7','8','9']\n",
        "#@markdown If the two sequences (query and input file) are different, the pipeline will align them and use only the matching position.\n",
        "print_aligned_sequences = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "print('-> upload pdb file:')\n",
        "pdb_path = f\"{jobname}_inputs\"\n",
        "uploaded_pdb = files.upload()\n",
        "\n",
        "for fn in uploaded_pdb.keys():\n",
        "  os.rename(fn, f\"{jobname}_inputs/{fn}\")\n",
        "\n",
        "  print('--> pdb loaded')\n",
        "  print()\n",
        "  wcn_scores=WCN(f\"{jobname}_inputs/{fn}\",'ca',query_sequence,chain=int(pdb_chain),print_sequences=print_aligned_sequences)\n",
        "  print('---> wcn evaluated')\n",
        "  loaded_pdb = True\n",
        "\n",
        "histogram_data(wcn_scores.flatten(),range_data=[0,20],xlabel='Weighted Contact Number',title=jobname+'_WCN',where_save=plot_folder)\n"
      ],
      "metadata": {
        "id": "4aPN1_Y7LJeO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'>DATA PREPROCESSING:</b></font> load GEMME file\n",
        "\n",
        "\n",
        "print('-> upload GEMME file:')\n",
        "gemme_path = f\"{jobname}_inputs\"\n",
        "uploaded_gemme = files.upload()\n",
        "#@markdown Run the cell to open the upload request and load $\\Delta \\Delta E$ mutagenesis file  -  the file format description is shown on the bottom of the notebook.\\\n",
        "#@markdown \\\n",
        "#@markdown **Select GEMME file format:**\n",
        "#@markdown - GEMME webserver format (use the file: <font color='#009e74'>\"normPred_evolCombi.txt\"</font></b> as input.  MSA creation steps [here](https://colab.research.google.com/github/KULL-Centre/_2022_functional-sites-cagiada/blob/main/MSA_for_GEMMEwebserver.ipynb) and link to [GEMME webserver](http://www.lcqb.upmc.fr/GEMME/submit.html)). **IF** you are using this option the query and the file sequences <b><font color='#D55C00'>HAVE TO MATCH</font></b>.\n",
        "#@markdown - Pipeline format (already formatted, two columns:  [W2M, score], see github for complete example)\n",
        "\n",
        "\n",
        "GEMME_file_format = \"GEMME webserver format\" #@param [\"Pipeline format\", \"GEMME webserver format\"]\n",
        "\n",
        "#@markdown If the two sequences (query and input file) are different, the pipeline will align them and use only the matching position.\n",
        "print_aligned_sequences = True #@param {type:\"boolean\"}\n",
        "import mdtraj as md\n",
        "\n",
        "for fn in uploaded_gemme.keys():\n",
        "    os.rename(fn, f\"{jobname}_inputs/{fn}\")\n",
        "    print('--> GEMME file found')\n",
        "\n",
        "    if GEMME_file_format == \"GEMME webserver format\":\n",
        "      input_gemme=pd.read_csv(f\"{jobname}_inputs/{fn}\",delim_whitespace=True)\n",
        "      GEMME_to_prism(input_gemme,query_sequence,f\"{jobname}_inputs/reformatted_{fn}\",0)\n",
        "      gemme_scores=load_data(f\"{jobname}_inputs/reformatted_{fn}\",query_sequence,print_sequences=print_aligned_sequences)\n",
        "    else:\n",
        "      gemme_scores=load_data(f\"{jobname}_inputs/{fn}\",query_sequence,print_sequences=print_aligned_sequences)\n",
        "  \n",
        "      print('---> GEMME scores loaded')\n",
        "\n",
        "gemme_scores=remove_WT_score(gemme_scores,query_sequence)\n",
        "gemme_scores_mean=np.nanmean(gemme_scores,axis=-1)\n",
        "\n",
        "print('---> GEMME mean score evaluated')\n",
        "histogram_data(gemme_scores.flatten(),range_data=[-7,0],xlabel='GEMME $\\Delta \\Delta E$',title=jobname+'_GEMME',where_save=plot_folder)\n",
        "loaded_gemme = True"
      ],
      "metadata": {
        "id": "beWu6ehvPpZz",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'>DATA PREPROCESSING:</font> Evaluating extra necessary features\n",
        "#@markdown Run the cell to evaluate the extra necessary features, including:\n",
        "#@markdown - $\\Delta \\Delta G$ and conservation neighbor scores\n",
        "#@markdown - Weighted contact number\n",
        "\n",
        "rosetta_neigbour_scores=neighbor_scores(rosetta_scores_mean,1)\n",
        "\n",
        "gemme_neigbour_scores=neighbor_scores(gemme_scores_mean,1)\n",
        "\n",
        "\n",
        "hydrophobicity_mut=np.empty((len(query_sequence),20),dtype=float)\n",
        "hydrophobicity_mut[:]=np.nan\n",
        "\n",
        "for i in range(len(query_sequence)):\n",
        "    for j in range(20):\n",
        "        hydrophobicity_mut[i,j]=AA_to_hydrophobicity_scores[alphabetAA_D_L[j+1]]\n",
        "\n",
        "loaded_extra=True"
      ],
      "metadata": {
        "id": "JScHImm0W4hF",
        "cellView": "form"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'>MODEL RUN:</font> Variant prediction and residue classification\n",
        "#@markdown Run the cell to use the trained catboost model and generate predictions for the query protein at variant and residue level.\n",
        "from catboost import CatBoostClassifier\n",
        "from glob import glob\n",
        "if ((loaded_ddg) and (loaded_gemme) and (loaded_pdb) and (loaded_extra)):\n",
        "  cat=CatBoostClassifier()\n",
        "  X,map=features_validation([gemme_scores,rosetta_scores, gemme_scores_mean,rosetta_scores_mean,hydrophobicity_mut,gemme_neigbour_scores,rosetta_neigbour_scores,wcn_scores],query_sequence)\n",
        "  if ddG_file_format == 'Rosetta':\n",
        "    if os.path.exists('./cat_trained_24jun22.cbm'):\n",
        "      cat.load_model(\"./cat_trained_24jun22.cbm\")\n",
        "    else:\n",
        "      print(f'Error: missing/incorrect model')\n",
        "  else:\n",
        "    if os.path.exists('./cat_gemme_af_cavity_13apr23.cbm'):\n",
        "        cat.load_model(\"./cat_gemme_af_cavity_13apr23.cbm\")\n",
        "    else:\n",
        "      print(f'Error: missing/incorrect model')\n",
        "\n",
        "  print(f\"-> Model loaded\")\n",
        "\n",
        "  prediction=cat.predict(X)\n",
        "\n",
        "  print(f\"--> Prediction succeed \")\n",
        "\n",
        "  variant_pred=np.empty((len(query_sequence),20),dtype=float)\n",
        "  variant_pred[:]=np.nan\n",
        "\n",
        "  for i,(n,m) in enumerate(zip(map,prediction)):\n",
        "    variant_pred[n[0],n[1]]=m\n",
        "\n",
        "  print(f\"---> Variant score evaluated\")\n",
        "\n",
        "  residue_mode_pred=retrieve_residue_label_pred(prediction,map,query_sequence,0.5)\n",
        "\n",
        "  print(f\"----> Residue score evaluated\")\n",
        "\n",
        "else:\n",
        "  if loaded_ddg!=True:\n",
        "    print(f'Error: missing ddGs')\n",
        "  if loaded_gemme!=True:\n",
        "    print(f'Error: missing GEMME scores')\n",
        "  if loaded_pdb!=True:\n",
        "      print(f'Error: missing pdb and wcn scores')\n",
        "  if loaded_extra!=True:\n",
        "      print(f'Error: missing additional feature scores')"
      ],
      "metadata": {
        "id": "zlI5_0GC8yfn",
        "collapsed": true,
        "cellView": "form",
        "outputId": "3b47fd41-38a7-4424-96fc-14cdb05dc9cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> Model loaded\n",
            "--> Prediction succeed \n",
            "---> Variant score evaluated\n",
            "----> Residue score evaluated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'>Show results: </font>\n",
        "#@markdown Plot and save the results of the classification for variants and residues of the query sequence\\\n",
        "#@markdown \\\n",
        "#@markdown **Color keys:**\n",
        "#@markdown - <b><font color='#009E74'>GREEN </font></b>: WT-like (variant and residue)\n",
        "#@markdown - <b><font color='#56b4e9'>BLUE </font></b>: Stable but inactive (variant) or **functional position** (residue)\n",
        "#@markdown - <b><font color='#D55C00'>RED </font></b>: Total-loss (variant and residue)\n",
        "#@markdown - <b><font color='#F0E442'>YELLOW </font></b>: Active but unstable (variant)\n",
        "#@markdown - <b>GRAY</b>: Class not assigned (residue)\n",
        "\n",
        "#@markdown \\\n",
        "#@markdown **N.B.:** residue numeration in the plots starts from 0.\n",
        "\n",
        "heatmap_classes_reordered(variant_pred,'\\u0394\\u0394G [a.u]',query_sequence,[0,len(query_sequence)-1],WT_cmap='coolwarm',xtick_spacing=20,figs=[40,6],where_save=plot_folder,title_figure=jobname)\n",
        "\n",
        "residues_classes_reordered(residue_mode_pred,[0,len(query_sequence)-1],title_figure=jobname,where_save=plot_folder,figs=[40,1],xtick_spacing=50)"
      ],
      "metadata": {
        "id": "XEoM_DZGbtaC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'>DOWNLOAD RESULTS: </font>\n",
        "\n",
        "mutation_list=[]\n",
        "residue_list=[]\n",
        "for i in range(0,len(query_sequence)):\n",
        "  residue_list.append(query_sequence[i]+str(i+1))\n",
        "  for j in range(20):\n",
        "    mutation_list.append(query_sequence[i]+str(i+1)+alphabetAA_D_L[j+1])\n",
        "\n",
        "\n",
        "print_feature_df=pd.DataFrame({'Mutation': np.array(mutation_list).flatten(),\n",
        "                        'GEMME variant' : gemme_scores.flatten(),'GEMME mean residue' : np.tile(gemme_scores_mean,(20,1)).T.flatten(), 'GEMME neighbours' : np.tile(gemme_neigbour_scores,(20,1)).T.flatten(),\n",
        "                        'Rosetta ddG variant' : rosetta_scores_norm.flatten() ,'Rosetta ddG mean residue' :  np.tile(rosetta_scores_mean,(20,1)).T.flatten(),'Rosetta ddG neigbours' : np.tile(rosetta_neigbour_scores,(20,1)).T.flatten(),\n",
        "                       'Hydrophobicity variant' : hydrophobicity_mut.flatten(), 'WCN residue' :  np.tile(wcn_scores,(20,1)).T.flatten()})\n",
        "\n",
        "print_variant_df=pd.DataFrame({'Mutation': np.array(mutation_list).flatten(),\n",
        "                        'Variant class ' : np.vectorize(alphabet_class_variant_d_l.get)(variant_pred.flatten()),'Variant class (digit)' : variant_pred.flatten()})\n",
        "\n",
        "print_residue_df=pd.DataFrame({'Residue': np.array(residue_list).flatten(),\n",
        "                        'Residue class ' : np.vectorize(alphabet_class_residue_d_l.get)(residue_mode_pred.flatten()),'Residue class (digit)' : residue_mode_pred.flatten(),\n",
        "                        '# WT-like variant' : count_class_variant_position(variant_pred,0),'# SBI variant' : count_class_variant_position(variant_pred,1),'# Total-loss variant' : count_class_variant_position(variant_pred,2)})\n",
        "\n",
        "## print files:\n",
        "#@markdown Select the output format for the result files:\n",
        "output_format = \"csv\" #@param [\"csv\",\"excel\"]\n",
        "#@markdown Mark the next box if you want a zip file with results (if not file will be store in the colab output folder)\n",
        "download_results = True #@param {type:\"boolean\"}\n",
        "if output_format== 'csv':\n",
        "  print_feature_df.to_csv(f\"{jobname}_outputs/\"+f\"{jobname}_variant_features.csv\",sep=',')\n",
        "  print_variant_df.to_csv(f\"{jobname}_outputs/\"+f\"{jobname}_variant_predictions.csv\",sep=',')\n",
        "  print_residue_df.to_csv(f\"{jobname}_outputs/\"+f\"{jobname}_residue_predictions.csv\",sep=',')\n",
        "\n",
        "if output_format== 'excel':\n",
        "  print_feature_df.to_excel(f\"{jobname}_outputs/\"+f\"{jobname}_variant_features.xlsx\")\n",
        "  print_variant_df.to_excel(f\"{jobname}_outputs/\"+f\"{jobname}_variant_predictions.xlsx\")\n",
        "  print_residue_df.to_excel(f\"{jobname}_outputs/\"+f\"{jobname}_residue_predictions.xlsx\")\n",
        "  \n",
        "  \n",
        "if download_results:\n",
        "  os.system( \"zip -r {} {}\".format( f\"{jobname}_outputs.zip\" , f\"{jobname}_outputs\" ) )\n",
        "  files.download(f\"{jobname}_outputs.zip\")\n"
      ],
      "metadata": {
        "id": "HdIPxqSE6zWi",
        "cellView": "form",
        "outputId": "8a6f5836-17a9-483b-a9a7-1bf5d4745dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d6eea28b-e5cb-4601-a403-29899da4217a\", \"test_outputs.zip\", 469026)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><font color='#56b4e9'>EXTRA </font></b>\n",
        "\n",
        "\\\\\n",
        "\n",
        "**File Format**\n",
        "\n",
        "Custom input files containing the conservation scores or thremodynamic stability changes should be formatted to be used in the pipeline. An example is shown here:\n",
        "\n",
        "\\\\\n",
        "\n",
        ">INPUT FILE EXAMPLE:\n",
        "\n",
        ">For a target protein with 45 residues, the scores file should be formatted like this: \n",
        "\n",
        ">Mutation  Score\n",
        "\n",
        ">M1A       2.4  \n",
        "M1C       1.2  \n",
        "..  \n",
        "M1=\n",
        "M1W       1.3  \n",
        "C2A       0.2   \n",
        "..  \n",
        "..  \n",
        "Y45W       0.3\n",
        "  \n",
        ">N.B.: Synonymous mutations should be skipped or reported as mutation to =. Stop mutations has to been removed from the list.\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Known problems:**\n",
        "\n",
        "- Residues with numeration index below 0 are not supported by the output file parser and thus they deleted from the pdb in the pre-processing step.\n",
        "- Insertions, deletions or missenses in any of the input file sequences (scores and PDB) compared to the query sequence are resolved using the Biopython alignment function. If the difference between the input sequences is too large, this may lead to incorrect alignment.\n",
        "\n",
        "\\\\\n",
        "\n",
        "**License:**\n",
        "\n",
        "The source code and model's parameters are licensed under the permissive Apache Licence, Version 2.0.\n",
        " Additionally, this notebook uses the reduce source code which license could be find in `/content/src/pdb_parser_scripts/reduce/`\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Bugs:**\n",
        "\n",
        "For any bugs please report the issue on the project [Github](https://github.com/KULL-Centre/_2022_functional-sites-cagiada) or contact one of the listed authors in the connected [manuscript](https://www.biorxiv.org/content/10.1101/2022.07.14.500015v1.full).\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Citing this work:**\n",
        "\n",
        "If you use our model please cite:\n",
        "\n",
        "Cagiada, M., Bottaro, S., Lindemose, S., Schenstrøm, S. M., Stein, A., Hartmann-Petersen, R., & Lindorff-Larsen, K. (2022). Discovering functionally important sites in proteins. bioRxiv, 2022-07.\n",
        "\n",
        "```\n",
        "@article{cagiada2022discovering,\n",
        "  title={Discovering functionally important sites in proteins},\n",
        "  author={Cagiada, Matteo and Bottaro, Sandro and Lindemose, S{\\o}ren and Schenstr{\\o}m, Signe M and Stein, Amelie and Hartmann-Petersen, Rasmus and Lindorff-Larsen, Kresten},\n",
        "  journal={bioRxiv},\n",
        "  pages={2022--07},\n",
        "  year={2022},\n",
        "  publisher={Cold Spring Harbor Laboratory}\n",
        "}\n",
        "```\n"
      ],
      "metadata": {
        "id": "0NULd4ycW4dw"
      }
    }
  ]
}